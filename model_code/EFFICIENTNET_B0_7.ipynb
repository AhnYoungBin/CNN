{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EFFICIENTNET_B0_7.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP2vmAm1f1/s0AHH0FbWKRH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"J_9sLM35wWuN","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import math"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ETygo3SHodmH","colab_type":"code","colab":{}},"source":["#음수의 값을 표현하기 위함.\n","def swish_activation(x):\n","  return x * tf.nn.sigmoid(x)\n","\n","#width 조건 설정.\n","def round_filters(filters, multiplier):\n","    depth_divisor = 8\n","    min_depth = None\n","    min_depth = min_depth or depth_divisor\n","    filters = filters * multiplier\n","    new_filters = max(min_depth, int(filters + depth_divisor / 2) // depth_divisor * depth_divisor)\n","    if new_filters < 0.9 * filters:\n","        new_filters += depth_divisor\n","    return int(new_filters)\n","\n","#depth 조건 설정.\n","def round_repeats(repeats, multiplier):\n","    if not multiplier:\n","        return repeats\n","    return int(math.ceil(multiplier * repeats))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9LJoLcXi369l","colab_type":"code","colab":{}},"source":["class EfficientNet_classification(tf.keras.layers.Layer):\n","  def __init__(self, pooling='avg', classes=1):\n","    super(EfficientNet_classification, self).__init__()\n","    self.classes = classes\n","    self.pooling = pooling\n","\n","    self.avg_pooling = tf.keras.layers.GlobalAveragePooling2D()\n","    self.max_pooling = tf.keras.layers.GlobalMaxPooling2D()\n","\n","    self.sigmoid_fc = tf.keras.layers.Dense(units=classes, activation=tf.keras.activations.sigmoid)\n","    self.softmax_fc = tf.keras.layers.Dense(units=classes, activation=tf.keras.activations.softmax)\n","\n","\n","  def call(self, inputs):\n","    if self.pooling == 'avg':\n","      x = self.avg_pooling(inputs)\n","    elif self.pooling == 'max':\n","      x = self.max_pooling(inputs)\n","\n","    if self.classes == 1:\n","      x = self.sigmoid_fc(x)\n","    else:\n","      x = self.softmax_fc(x)\n","      \n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z55WxW0JoySj","colab_type":"code","colab":{}},"source":["class MBConv(tf.keras.layers.Layer):\n","  def __init__(self, kernel_size, input_filters, output_filters, \\\n","                              expand_ratio, stride, id_skip, se_ratio):\n","    super(MBConv, self).__init__()\n","    '''Organized separately from active call parts.'''\n","    self.stride = stride\n","    self.input_filters = input_filters\n","    self.output_filters = output_filters\n","\n","    # expansion phase\n","    self.conv_1 = tf.keras.layers.Conv2D(filters = input_filters*expand_ratio, \n","                                          kernel_size=(1, 1),  \n","                                          padding='same',\n","                                         use_bias=False)\n","    self.bn_1 = tf.keras.layers.BatchNormalization()\n","\n","    # Depthwise convolution phase\n","    self.dw_conv_1 = tf.keras.layers.DepthwiseConv2D(kernel_size = kernel_size, \n","                                                     strides = stride,  \n","                                                     padding='same',\n","                                                     use_bias=False)\n","    self.bn_2 = tf.keras.layers.BatchNormalization()\n","\n","    # Squeeze and excitation phase\n","    self.se_1 = tf.keras.layers.GlobalAveragePooling2D()\n","    self.squeezed_filters = max (1, int(input_filters * se_ratio))\n","\n","    self.se_3 = tf.keras.layers.Conv2D(filters = self.squeezed_filters, \n","                                       kernel_size=(1, 1), \n","                                       padding='same')\n","    self.se_4 = tf.keras.layers.Conv2D(filters = input_filters*expand_ratio, \n","                                       kernel_size=(1, 1), \n","                                       padding='same')\n","    # Output phase\n","    self.conv_2 = tf.keras.layers.Conv2D(filters = output_filters, \n","                                         kernel_size=(1, 1), \n","                                         padding='same',\n","                                         use_bias=False)\n","    self.bn_3 = tf.keras.layers.BatchNormalization()\n","\n","  def call(self, inputs):\n","    # expansion phase\n","    x = self.conv_1(inputs)\n","    x = self.bn_1(x)\n","    x = swish_activation(x)\n","    # Depthwise convolution phase\n","    x = self.dw_conv_1(x)\n","    x = self.bn_2(x)\n","    # Squeeze and excitation phase\n","    se = self.se_1(x)\n","    branch = tf.expand_dims(input=se, axis=1)\n","    branch = tf.expand_dims(input=se, axis=1)\n","    se = self.se_3(se)\n","    se = swish_activation(se)\n","    se = self.se_4(se)\n","    se = tf.nn.sigmoid(se)\n","    x = x * se\n","    x = swish_activation(x)\n","    # Output phase\n","    x = self.conv_2(x)\n","    x = self.bn_3(x)\n","    if self.stride == 1 and self.input_filters == self.output_filters:\n","      x = tf.keras.layers.add([x, inputs])\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"j0JZWljeLqcv","colab_type":"code","colab":{}},"source":["def build_MBConv(kernel_size, num_repeat, input_filters, output_filters, \\\n","                 expand_ratio, stride, id_skip=True, se_ratio=0.25, depth=None, width=None):\n","  mbConv_block = tf.keras.Sequential()\n","  depth_layer = round_repeats(num_repeat, depth)\n","  for i in range(depth_layer):\n","    if i == 0:\n","      input_filter = round_repeats(input_filters, width)\n","      output_filter = round_repeats(output_filters, width)\n","      mbConv_block.add(MBConv(kernel_size, input_filter, output_filter, \\\n","                              expand_ratio, stride, id_skip, se_ratio))\n","    else:\n","      input_filter = round_repeats(input_filters, width)\n","      output_filter = round_repeats(output_filters, width)\n","      mbConv_block.add(MBConv(kernel_size, input_filter, output_filter, \\\n","                              expand_ratio, 1, id_skip, se_ratio))\n","  return mbConv_block"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8IwARKMRmt4f","colab_type":"code","colab":{}},"source":["class EfficientNet(tf.keras.Model):\n","  def __init__(self, width, depth, pool='avg', classes=1000, include_top=True):\n","    super(EfficientNet, self).__init__()\n","\n","    self.conv_1 = tf.keras.layers.Conv2D(filters=round_filters(32, width),\n","                                         kernel_size=(3, 3),\n","                                         strides=2,\n","                                         padding=\"same\")\n","    self.bn_1 = tf.keras.layers.BatchNormalization()\n","\n","    self.MBConv_1 = build_MBConv(kernel_size=(3, 3), num_repeat=1, input_filters=32, \\\n","                                 output_filters=16, expand_ratio=1, stride=1, id_skip=True, se_ratio=0.25, depth=depth, width=width)\n","    self.MBConv_2 = build_MBConv(kernel_size=(3, 3), num_repeat=2, input_filters=16, \\\n","                                 output_filters=24, expand_ratio=6, stride=2, id_skip=True, se_ratio=0.25, depth=depth, width=width)\n","    self.MBConv_3 = build_MBConv(kernel_size=(5, 5), num_repeat=2, input_filters=24, \\\n","                                 output_filters=40, expand_ratio=6, stride=2, id_skip=True, se_ratio=0.25, depth=depth, width=width)\n","    self.MBConv_4 = build_MBConv(kernel_size=(3, 3), num_repeat=3, input_filters=40, \\\n","                                 output_filters=80, expand_ratio=6, stride=2, id_skip=True, se_ratio=0.25, depth=depth, width=width)\n","    self.MBConv_5 = build_MBConv(kernel_size=(5, 5), num_repeat=3, input_filters=80, \\\n","                                 output_filters=112, expand_ratio=6, stride=1, id_skip=True, se_ratio=0.25, depth=depth, width=width)\n","    self.MBConv_6 = build_MBConv(kernel_size=(5, 5), num_repeat=4, input_filters=112, \\\n","                                 output_filters=192, expand_ratio=6, stride=2, id_skip=True, se_ratio=0.25, depth=depth, width=width)\n","    self.MBConv_7 = build_MBConv(kernel_size=(3, 3), num_repeat=1, input_filters=192, \\\n","                                 output_filters=320, expand_ratio=6, stride=1, id_skip=True, se_ratio=0.25, depth=depth, width=width)\n","\n","    self.conv_2 = tf.keras.layers.Conv2D(filters=round_filters(1280, width),\n","                                        kernel_size=(1, 1),\n","                                        strides=1,\n","                                        padding=\"same\")\n","    self.bn_2 = tf.keras.layers.BatchNormalization()\n","    self.fc = EfficientNet_classification(pooling=pool, classes=classes)\n","  def call(self, inputs):\n","    x = self.conv_1(inputs)\n","    x = self.bn_1(x)\n","    x = self.MBConv_1(x)\n","    x = self.MBConv_2(x)\n","    x = self.MBConv_3(x)\n","    x = self.MBConv_4(x)\n","    x = self.MBConv_5(x)\n","    x = self.MBConv_6(x)\n","    x = self.MBConv_7(x)\n","    x = self.conv_2(x)\n","    x = self.bn_2(x)\n","    x = self.fc(x)\n","\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5aBhCXmP7JMa","colab_type":"text"},"source":["kernel_size는 컨볼 루션의 커널 크기입니다. 예 : 3 x 3\n","\n","num_repeat는 특정 블록을 몇 번 반복해야하는지 지정합니다. 0보다 커야합니다.\n","\n","input_filters 및 output_filters는 지정된 필터 수입니다.\n","\n","expand_ratio는 입력 필터 확장 비율입니다.\n","\n","id_skip는 건너 뛰기 연결 사용 여부를 제안합니다\n","\n","se_ratio는 압착 및 여기 블록에 대한 압착 비율을 제공합니다"]},{"cell_type":"code","metadata":{"id":"J3XHtMaX5A7H","colab_type":"code","colab":{}},"source":["def get_efficient_net(width_coefficient, depth_coefficient, resolution, pool='avg', classes=1000, include_top=True):\n","    return EfficientNet(width=width_coefficient, depth=depth_coefficient, pool=pool, classes=classes, include_top=include_top)\n","\n","def efficient_net_b0():\n","    return get_efficient_net(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, pool='avg', classes=1000, include_top=True)\n","\n","\n","def efficient_net_b1():\n","    return get_efficient_net(width_coefficient=1.0, depth_coefficient=1.1, resolution=244, pool='avg', classes=1000, include_top=True)\n","\n","\n","def efficient_net_b2():\n","    return get_efficient_net(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, pool='avg', classes=1000, include_top=True)\n","\n","\n","def efficient_net_b3():\n","    return get_efficient_net(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, pool='avg', classes=1000, include_top=True)\n","\n","\n","def efficient_net_b4():\n","    return get_efficient_net(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, pool='avg', classes=1000, include_top=True)\n","\n","\n","def efficient_net_b5():\n","    return get_efficient_net(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, pool='avg', classes=1000, include_top=True)\n","\n","\n","def efficient_net_b6():\n","    return get_efficient_net(width_coefficient=1.8, depth_coefficient=2.6, resolution=580, pool='avg', classes=1000, include_top=True)\n","\n","\n","def efficient_net_b7():\n","    return get_efficient_net(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, pool='avg', classes=1000, include_top=True)\n"],"execution_count":0,"outputs":[]}]}