{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EFFICIENTNET_only_B0.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMlYiosb3cMibfbDgPRmwU6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"HOiTssEBwIth","colab_type":"code","outputId":"3fa942a1-75fe-45b0-ad36-9da2df4dc552","executionInfo":{"status":"ok","timestamp":1583594879536,"user_tz":-540,"elapsed":67232,"user":{"displayName":"정규준","photoUrl":"","userId":"06773425004265186105"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["!pip install -q tensorflow-gpu==2.0.0-rc1"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 380.5MB 44kB/s \n","\u001b[K     |████████████████████████████████| 4.3MB 39.9MB/s \n","\u001b[K     |████████████████████████████████| 501kB 35.2MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nyFm9af4wfJz","colab_type":"code","outputId":"b0e5d362-623b-48ca-c80f-5da19287bce5","executionInfo":{"status":"ok","timestamp":1583594988717,"user_tz":-540,"elapsed":176402,"user":{"displayName":"정규준","photoUrl":"","userId":"06773425004265186105"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install tf-nightly-gpu"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting tf-nightly-gpu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/51/bf50d881a68915774f7d803ed7e7dc7dd9da513f92e8464b8e396463bf49/tf_nightly_gpu-2.2.0.dev20200307-cp36-cp36m-manylinux2010_x86_64.whl (516.9MB)\n","\u001b[K     |████████████████████████████████| 516.9MB 30kB/s \n","\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.12.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.1.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.17.5)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.34.2)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.1.8)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (3.10.0)\n","Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (3.1.0)\n","Collecting gast==0.3.3\n","  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n","Collecting h5py<2.11.0,>=2.10.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/06/cafdd44889200e5438b897388f3075b52a8ef01f28a17366d91de0fa2d05/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 44.9MB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.27.1)\n","Collecting astunparse==1.6.3\n","  Downloading https://files.pythonhosted.org/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.1.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.9.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.11.2)\n","Requirement already satisfied: tf-estimator-nightly in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.14.0.dev2019080601)\n","Collecting tb-nightly<2.3.0a0,>=2.2.0a0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/d7/ec7206a549af414383b788614371996a7351e1075e4a8aabbd6d714cc4cf/tb_nightly-2.2.0a20200307-py3-none-any.whl (2.8MB)\n","\u001b[K     |████████████████████████████████| 2.8MB 33.9MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tf-nightly-gpu) (45.2.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly-gpu) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly-gpu) (3.2.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly-gpu) (1.7.2)\n","Collecting tensorboard-plugin-wit>=1.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/ec/3da49289b93963bd8b32d29ed108f1809436ff3d9cd4e29c90bac4a7292f/tensorboard_plugin_wit-1.6.0.post2-py3-none-any.whl (775kB)\n","\u001b[K     |████████████████████████████████| 778kB 43.8MB/s \n","\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly-gpu) (2.21.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly-gpu) (0.4.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly-gpu) (0.2.8)\n","Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly-gpu) (4.0)\n","Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly-gpu) (3.1.1)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly-gpu) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly-gpu) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly-gpu) (2019.11.28)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly-gpu) (3.0.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly-gpu) (1.3.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly-gpu) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly-gpu) (3.1.0)\n","\u001b[31mERROR: tensorflow 1.15.0 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow-gpu 2.0.0rc1 has requirement tb-nightly<1.15.0a20190807,>=1.15.0a20190806, but you'll have tb-nightly 2.2.0a20200307 which is incompatible.\u001b[0m\n","Installing collected packages: gast, h5py, astunparse, tensorboard-plugin-wit, tb-nightly, tf-nightly-gpu\n","  Found existing installation: gast 0.2.2\n","    Uninstalling gast-0.2.2:\n","      Successfully uninstalled gast-0.2.2\n","  Found existing installation: h5py 2.8.0\n","    Uninstalling h5py-2.8.0:\n","      Successfully uninstalled h5py-2.8.0\n","  Found existing installation: tb-nightly 1.15.0a20190806\n","    Uninstalling tb-nightly-1.15.0a20190806:\n","      Successfully uninstalled tb-nightly-1.15.0a20190806\n","Successfully installed astunparse-1.6.3 gast-0.3.3 h5py-2.10.0 tb-nightly-2.2.0a20200307 tensorboard-plugin-wit-1.6.0.post2 tf-nightly-gpu-2.2.0.dev20200307\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"L-rBoR6-xRmH","colab_type":"code","outputId":"5c569753-f646-4386-b6e9-0b94f7881d4f","executionInfo":{"status":"ok","timestamp":1583595030815,"user_tz":-540,"elapsed":218493,"user":{"displayName":"정규준","photoUrl":"","userId":"06773425004265186105"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["# mount to your google drive\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"We2_8fr8xATv","colab_type":"code","outputId":"25b24992-7f1f-493a-9496-f137d106ddc8","executionInfo":{"status":"ok","timestamp":1583595035582,"user_tz":-540,"elapsed":223251,"user":{"displayName":"정규준","photoUrl":"","userId":"06773425004265186105"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","import tensorflow as tf\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","import os\n","import numpy as np\n","import math\n","import matplotlib.pyplot as plt\n","\n","print(tf.__version__)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["2.2.0-dev20200307\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_M3dqnahxHYj","colab_type":"code","colab":{}},"source":["PATH = '/content/gdrive/My Drive/dataset/'\n","\n","train_dir = os.path.join(PATH, 'train')\n","validation_dir = os.path.join(PATH, 'val')\n","test_dir = os.path.join(PATH, 'test')\n","\n","train_cats_dir = os.path.join(train_dir, 'cat')  # directory with our training cat pictures\n","train_dogs_dir = os.path.join(train_dir, 'dog')  # directory with our training dog pictures\n","validation_cats_dir = os.path.join(validation_dir, 'cat')  # directory with our validation cat pictures\n","validation_dogs_dir = os.path.join(validation_dir, 'dog')  # directory with our validation dog pictures\n","test_cats_dir = os.path.join(test_dir, 'cat')\n","test_dogs_dir = os.path.join(test_dir, 'dog')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ilYyHJdOx3GR","colab_type":"code","colab":{}},"source":["num_cats_tr = len(os.listdir(train_cats_dir))\n","num_dogs_tr = len(os.listdir(train_dogs_dir))\n","\n","num_cats_val = len(os.listdir(validation_cats_dir))\n","num_dogs_val = len(os.listdir(validation_dogs_dir))\n","\n","num_cats_test = len(os.listdir(test_cats_dir))\n","num_dogs_test = len(os.listdir(test_dogs_dir))\n","\n","total_train = num_cats_tr + num_dogs_tr\n","total_val = num_cats_val + num_dogs_val\n","total_test = num_cats_test + num_dogs_test"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mHYcrDwIaUSZ","colab_type":"code","colab":{}},"source":["def plot_value_array(i, data, title):\n","  plt.ylabel('num of image')\n","  plt.title(\"{}_data\".format(title))\n","  plt.bar(range(len(data)), data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MjzA80asaU2l","colab_type":"code","outputId":"46a8cc09-46ea-43a1-e717-11324dfc4177","executionInfo":{"status":"ok","timestamp":1583597849089,"user_tz":-540,"elapsed":37025,"user":{"displayName":"정규준","photoUrl":"","userId":"06773425004265186105"}},"colab":{"base_uri":"https://localhost:8080/","height":301}},"source":["datas = [num_cats_tr, num_dogs_tr, num_cats_val, num_dogs_val, num_cats_test, num_dogs_test]\n","\n","plt.figure(figsize=(15, 4))\n","plot_value_array(1, datas,'train, val, test data(each cat, dog)')"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAA4EAAAEICAYAAADhivH1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n","text/plain":["<Figure size 1080x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"TX63kKEjwg_C","colab_type":"code","outputId":"5b6d0ace-41b2-48f4-ed85-efaec22d067e","executionInfo":{"status":"ok","timestamp":1583597849863,"user_tz":-540,"elapsed":37613,"user":{"displayName":"정규준","photoUrl":"","userId":"06773425004265186105"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["#tensorflow loader\n","\n","batch_size = 20\n","epochs = 100\n","IMG_HEIGHT = 224\n","IMG_WIDTH = 224\n","\n","train_image_generator = ImageDataGenerator(rescale=1./255,\n","                                           rotation_range=40,\n","                                           shear_range=0.2,\n","                                           zoom_range=0.2,\n","                                           horizontal_flip=True,) # Generator for our training data\n","validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data\n","test_image_generator = ImageDataGenerator(rescale=1./255)\n","\n","train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n","                                                           directory=train_dir,\n","                                                           shuffle=True,\n","                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n","                                                           class_mode='binary')\n","val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n","                                                              directory=validation_dir,\n","                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n","                                                              class_mode='binary')\n","\n","test_data_gen = test_image_generator.flow_from_directory(batch_size=batch_size,\n","                                                              directory=validation_dir,\n","                                                              shuffle=False,\n","                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n","                                                              class_mode='binary')"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Found 17000 images belonging to 2 classes.\n","Found 4000 images belonging to 2 classes.\n","Found 4000 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J_9sLM35wWuN","colab_type":"code","colab":{}},"source":["#음수의 값을 표현하기 위함.\n","def swish_activation(x):\n","  return x * tf.nn.sigmoid(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9LJoLcXi369l","colab_type":"code","colab":{}},"source":["class EfficientNet_classification(tf.keras.layers.Layer):\n","  def __init__(self, pooling='avg', classes=1):\n","    super(EfficientNet_classification, self).__init__()\n","    self.classes = classes\n","    self.pooling = pooling\n","\n","    self.avg_pooling = tf.keras.layers.GlobalAveragePooling2D()\n","    self.max_pooling = tf.keras.layers.GlobalMaxPooling2D()\n","\n","    self.sigmoid_fc = tf.keras.layers.Dense(units=classes, activation=tf.keras.activations.sigmoid)\n","    self.softmax_fc = tf.keras.layers.Dense(units=classes, activation=tf.keras.activations.softmax)\n","\n","\n","  def call(self, inputs):\n","    if self.pooling == 'avg':\n","      x = self.avg_pooling(inputs)\n","    elif self.pooling == 'max':\n","      x = self.max_pooling(inputs)\n","\n","    if self.classes == 1:\n","      x = self.sigmoid_fc(x)\n","    else:\n","      x = self.softmax_fc(x)\n","      \n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z55WxW0JoySj","colab_type":"code","colab":{}},"source":["class MBConv_Block(tf.keras.layers.Layer):\n","  def __init__(self, block_arg):\n","    super(MBConv_Block, self).__init__()\n","\n","    self.kernel_size = block_arg['kernel_size']\n","    self.num_repeat= block_arg['num_repeat']\n","    self.input_filters= block_arg['input_filters']\n","    self.output_filters= block_arg['kernel_size']\n","    self.expand_ratio= block_arg['expand_ratio']\n","    self.id_skip= block_arg['id_skip']\n","    self.strides= block_arg['strides']\n","    self.se_ratio= block_arg['se_ratio']\n","\n","    # expansion phase\n","    self.expanded_filters =  self.input_filters * self.expand_ratio\n","    self.conv_1 = tf.keras.layers.Conv2D(filters = self.expanded_filters, \n","                                          kernel_size=(1, 1),  \n","                                          padding='same',  \n","                                          use_bias=False)\n","    self.bn_1 = tf.keras.layers.BatchNormalization()\n","\n","    # Depthwise convolution phase\n","    self.dw_conv_1 = tf.keras.layers.DepthwiseConv2D(kernel_size = self.kernel_size, \n","                                                     strides = self.strides,  \n","                                                     padding='same',  \n","                                                     use_bias=False)\n","    self.bn_2 = tf.keras.layers.BatchNormalization()\n","\n","    # Squeeze and excitation phase\n","    self.se_1 = tf.keras.layers.GlobalAveragePooling2D()\n","    self.se_2 = tf.keras.layers.Reshape((1, 1, self.expanded_filters ))\n","    self.squeezed_filters = max (1, int(self.input_filters * self.se_ratio))\n","\n","    # activation 뒤로 뺌. (call에서 처리 필요. - 둘 다, swish, sigmoid) \n","    self.se_3 = tf.keras.layers.Conv2D(filters = self.squeezed_filters, \n","                                       kernel_size=(1, 1), \n","                                       padding='same')\n","    self.se_4 = tf.keras.layers.Conv2D(filters = self.expanded_filters, \n","                                       kernel_size=(1, 1), \n","                                       padding='same')\n","    # Output phase\n","    self.conv_2 = tf.keras.layers.Conv2D(filters = self.output_filters, \n","                                         kernel_size=(1, 1), \n","                                         padding='same', \n","                                         use_bias=False)\n","    self.bn_3 = tf.keras.layers.BatchNormalization()\n","\n","  def call(self, inputs):\n","    # expansion phase\n","    x = self.conv_1(inputs)\n","    x = self.bn_1(x)\n","    x = swish_activation(x)\n","    # Depthwise convolution phase\n","    x = self.dw_conv_1(x)\n","    x = self.bn_2(x)\n","    x = swish_activation(x)\n","    # Squeeze and excitation phase\n","    se = self.se_1(x)\n","    se = self.se_2(x)\n","    se = self.se_3(x)\n","    se = swish_activation(x)\n","    se = self.se_4(x)\n","    se = tf.nn.sigmoid(x)\n","    x = tf.keras.layers.multiply([x, se])\n","    # Output phase\n","    x = self.conv_2(x)\n","    x = self.bn_3(x)\n","    \n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8IwARKMRmt4f","colab_type":"code","colab":{}},"source":["class EfficientNet(tf.keras.Model):\n","  def __init__(self, argument_block=None, pool='avg', classes=1000, include_top=True):\n","    super(EfficientNet, self).__init__()\n","    self.conv_1 = tf.keras.layers.Conv2D(filters=32,\n","                                         kernel_size=(3, 3),\n","                                         strides=2,\n","                                         padding=\"same\")\n","    self.bn_1 = tf.keras.layers.BatchNormalization()\n","\n","    self.efficientnet_1 = MBConv_Block(argument_block['BlockArgs_1'])\n","    self.efficientnet_2 = MBConv_Block(argument_block['BlockArgs_2'])\n","    self.efficientnet_3 = MBConv_Block(argument_block['BlockArgs_3'])\n","    self.efficientnet_4 = MBConv_Block(argument_block['BlockArgs_4'])\n","    self.efficientnet_5 = MBConv_Block(argument_block['BlockArgs_5'])\n","    self.efficientnet_6 = MBConv_Block(argument_block['BlockArgs_6'])\n","    self.efficientnet_7 = MBConv_Block(argument_block['BlockArgs_7'])\n","\n","    self.conv_2 = tf.keras.layers.Conv2D(filters=1280,\n","                                        kernel_size=(1, 1),\n","                                        strides=1,\n","                                        padding=\"same\")\n","    self.bn_2 = tf.keras.layers.BatchNormalization()\n","    self.fc = EfficientNet_classification(pooling=pool, classes=classes)\n","  def call(self, inputs):\n","    x = self.conv_1(inputs)\n","    x = self.bn_1(x)\n","    x = self.efficientnet_1(x)\n","    x = self.efficientnet_2(x)\n","    x = self.efficientnet_3(x)\n","    x = self.efficientnet_4(x)\n","    x = self.efficientnet_5(x)\n","    x = self.efficientnet_6(x)\n","    x = self.efficientnet_7(x)\n","    x = self.conv_2(x)\n","    x = self.bn_2(x)\n","    x = self.fc(x)\n","\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5aBhCXmP7JMa","colab_type":"text"},"source":["kernel_size는 컨볼 루션의 커널 크기입니다. 예 : 3 x 3\n","\n","num_repeat는 특정 블록을 몇 번 반복해야하는지 지정합니다. 0보다 커야합니다.\n","\n","input_filters 및 output_filters는 지정된 필터 수입니다.\n","\n","expand_ratio는 입력 필터 확장 비율입니다.\n","\n","id_skip는 건너 뛰기 연결 사용 여부를 제안합니다\n","\n","se_ratio는 압착 및 여기 블록에 대한 압착 비율을 제공합니다"]},{"cell_type":"code","metadata":{"id":"J3XHtMaX5A7H","colab_type":"code","colab":{}},"source":["#EfficientNetB0 블럭 하이퍼파라미터.\n","def efficient_B0():\n","  argument_block= {\n","      'BlockArgs_1':{'kernel_size':3, 'num_repeat':1, 'input_filters':32, 'output_filters':16, 'expand_ratio':1, 'id_skip':True, 'strides':[1, 1], 'se_ratio':0.25},\n","      'BlockArgs_2':{'kernel_size':3, 'num_repeat':2, 'input_filters':16, 'output_filters':24, 'expand_ratio':6, 'id_skip':True, 'strides':[2, 2], 'se_ratio':0.25},\n","      'BlockArgs_3':{'kernel_size':5, 'num_repeat':2, 'input_filters':24, 'output_filters':40, 'expand_ratio':6, 'id_skip':True, 'strides':[2, 2], 'se_ratio':0.25},\n","      'BlockArgs_4':{'kernel_size':3, 'num_repeat':3, 'input_filters':40, 'output_filters':80, 'expand_ratio':6, 'id_skip':True, 'strides':[2, 2], 'se_ratio':0.25},\n","      'BlockArgs_5':{'kernel_size':5, 'num_repeat':3, 'input_filters':80, 'output_filters':112, 'expand_ratio':6, 'id_skip':True, 'strides':[1, 1], 'se_ratio':0.25},\n","      'BlockArgs_6':{'kernel_size':5, 'num_repeat':4, 'input_filters':112, 'output_filters':192, 'expand_ratio':6, 'id_skip':True, 'strides':[2, 2], 'se_ratio':0.25},\n","      'BlockArgs_7':{'kernel_size':3, 'num_repeat':1, 'input_filters':192, 'output_filters':320, 'expand_ratio':6, 'id_skip':True, 'strides':[1, 1], 'se_ratio':0.25}\n","  }\n","\n","  return EfficientNet(argument_block=argument_block, pool='avg', classes=1, include_top=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"it_r_8WI5D-6","colab_type":"code","colab":{}},"source":["efficient_b0 = efficient_B0()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lWNeHDHZYKrQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":561},"outputId":"55e90352-3c45-4bad-8746-488f4a7d6a96","executionInfo":{"status":"ok","timestamp":1583607758641,"user_tz":-540,"elapsed":1235,"user":{"displayName":"정규준","photoUrl":"","userId":"06773425004265186105"}}},"source":["def print_model_summary(network):\n","    network.build(input_shape=(None, IMG_HEIGHT, IMG_WIDTH, 3))\n","    network.summary()\n","\n","print_model_summary(network=efficient_b0)"],"execution_count":210,"outputs":[{"output_type":"stream","text":["Model: \"efficient_net_35\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1049 (Conv2D)         multiple                  896       \n","_________________________________________________________________\n","batch_normalization_802 (Bat multiple                  128       \n","_________________________________________________________________\n","mb_conv__block_185 (MBConv_B multiple                  2996      \n","_________________________________________________________________\n","mb_conv__block_186 (MBConv_B multiple                  11920     \n","_________________________________________________________________\n","mb_conv__block_187 (MBConv_B multiple                  27674     \n","_________________________________________________________________\n","mb_conv__block_188 (MBConv_B multiple                  66262     \n","_________________________________________________________________\n","mb_conv__block_189 (MBConv_B multiple                  260200    \n","_________________________________________________________________\n","mb_conv__block_190 (MBConv_B multiple                  500016    \n","_________________________________________________________________\n","mb_conv__block_191 (MBConv_B multiple                  1412412   \n","_________________________________________________________________\n","conv2d_1078 (Conv2D)         multiple                  5120      \n","_________________________________________________________________\n","batch_normalization_824 (Bat multiple                  5120      \n","_________________________________________________________________\n","efficient_net_classification multiple                  1281      \n","=================================================================\n","Total params: 2,294,025\n","Trainable params: 2,280,083\n","Non-trainable params: 13,942\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I-1u3kWT_DTd","colab_type":"code","colab":{}},"source":["optimizer = tf.keras.optimizers.SGD(lr=0.001, momentum=0.9)\n","\n","efficient_b0.compile(optimizer=optimizer,\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PZxiZwmc_lt-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":343},"outputId":"e027ddca-eb3b-4282-8d3c-36bef515a7ff"},"source":["history = efficient_b0.fit_generator(\n","    train_data_gen,\n","    steps_per_epoch = 80,\n","    epochs=epochs,\n","    validation_data = val_data_gen,\n","    validation_steps = 20\n",")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","WARNING:tensorflow:Gradients do not exist for variables ['mb_conv__block_185/conv2d_1051/kernel:0', 'mb_conv__block_185/conv2d_1051/bias:0', 'mb_conv__block_185/conv2d_1052/kernel:0', 'mb_conv__block_185/conv2d_1052/bias:0', 'mb_conv__block_186/conv2d_1055/kernel:0', 'mb_conv__block_186/conv2d_1055/bias:0', 'mb_conv__block_186/conv2d_1056/kernel:0', 'mb_conv__block_186/conv2d_1056/bias:0', 'mb_conv__block_187/conv2d_1059/kernel:0', 'mb_conv__block_187/conv2d_1059/bias:0', 'mb_conv__block_187/conv2d_1060/kernel:0', 'mb_conv__block_187/conv2d_1060/bias:0', 'mb_conv__block_188/conv2d_1063/kernel:0', 'mb_conv__block_188/conv2d_1063/bias:0', 'mb_conv__block_188/conv2d_1064/kernel:0', 'mb_conv__block_188/conv2d_1064/bias:0', 'mb_conv__block_189/conv2d_1067/kernel:0', 'mb_conv__block_189/conv2d_1067/bias:0', 'mb_conv__block_189/conv2d_1068/kernel:0', 'mb_conv__block_189/conv2d_1068/bias:0', 'mb_conv__block_190/conv2d_1071/kernel:0', 'mb_conv__block_190/conv2d_1071/bias:0', 'mb_conv__block_190/conv2d_1072/kernel:0', 'mb_conv__block_190/conv2d_1072/bias:0', 'mb_conv__block_191/conv2d_1075/kernel:0', 'mb_conv__block_191/conv2d_1075/bias:0', 'mb_conv__block_191/conv2d_1076/kernel:0', 'mb_conv__block_191/conv2d_1076/bias:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['mb_conv__block_185/conv2d_1051/kernel:0', 'mb_conv__block_185/conv2d_1051/bias:0', 'mb_conv__block_185/conv2d_1052/kernel:0', 'mb_conv__block_185/conv2d_1052/bias:0', 'mb_conv__block_186/conv2d_1055/kernel:0', 'mb_conv__block_186/conv2d_1055/bias:0', 'mb_conv__block_186/conv2d_1056/kernel:0', 'mb_conv__block_186/conv2d_1056/bias:0', 'mb_conv__block_187/conv2d_1059/kernel:0', 'mb_conv__block_187/conv2d_1059/bias:0', 'mb_conv__block_187/conv2d_1060/kernel:0', 'mb_conv__block_187/conv2d_1060/bias:0', 'mb_conv__block_188/conv2d_1063/kernel:0', 'mb_conv__block_188/conv2d_1063/bias:0', 'mb_conv__block_188/conv2d_1064/kernel:0', 'mb_conv__block_188/conv2d_1064/bias:0', 'mb_conv__block_189/conv2d_1067/kernel:0', 'mb_conv__block_189/conv2d_1067/bias:0', 'mb_conv__block_189/conv2d_1068/kernel:0', 'mb_conv__block_189/conv2d_1068/bias:0', 'mb_conv__block_190/conv2d_1071/kernel:0', 'mb_conv__block_190/conv2d_1071/bias:0', 'mb_conv__block_190/conv2d_1072/kernel:0', 'mb_conv__block_190/conv2d_1072/bias:0', 'mb_conv__block_191/conv2d_1075/kernel:0', 'mb_conv__block_191/conv2d_1075/bias:0', 'mb_conv__block_191/conv2d_1076/kernel:0', 'mb_conv__block_191/conv2d_1076/bias:0'] when minimizing the loss.\n","80/80 [==============================] - 610s 8s/step - loss: 0.7048 - accuracy: 0.5113 - val_loss: 0.6941 - val_accuracy: 0.4500\n","Epoch 2/100\n","80/80 [==============================] - 597s 7s/step - loss: 0.6860 - accuracy: 0.5606 - val_loss: 0.6940 - val_accuracy: 0.4625\n","Epoch 3/100\n","80/80 [==============================] - 609s 8s/step - loss: 0.6738 - accuracy: 0.5750 - val_loss: 0.6913 - val_accuracy: 0.5375\n","Epoch 4/100\n","80/80 [==============================] - 586s 7s/step - loss: 0.6813 - accuracy: 0.5669 - val_loss: 0.6927 - val_accuracy: 0.5150\n","Epoch 5/100\n","80/80 [==============================] - 587s 7s/step - loss: 0.6748 - accuracy: 0.5569 - val_loss: 0.6926 - val_accuracy: 0.5200\n","Epoch 6/100\n","80/80 [==============================] - 587s 7s/step - loss: 0.6516 - accuracy: 0.6137 - val_loss: 0.6931 - val_accuracy: 0.5000\n","Epoch 7/100\n","80/80 [==============================] - 596s 7s/step - loss: 0.6535 - accuracy: 0.6069 - val_loss: 0.6939 - val_accuracy: 0.4800\n","Epoch 8/100\n","66/80 [=======================>......] - ETA: 1:08 - loss: 0.6461 - accuracy: 0.6076"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I7E-u5mt_tfO","colab_type":"code","colab":{}},"source":["# define loss and optimizer\n","    loss_object = tf.keras.losses.BinaryCrossentropy()\n","    optimizer = tf.keras.optimizers.SGD(lr=0.001, momentum=0.9)\n","\n","    train_loss = tf.keras.metrics.Mean(name='train_loss')\n","    train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n","\n","    valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n","    valid_accuracy = tf.keras.metrics.BinaryAccuracy(name='valid_accuracy')\n","\n","    # @tf.function\n","    def train_step(image_batch, label_batch):\n","        with tf.GradientTape() as tape:\n","            predictions = vgg16(image_batch, training=True)\n","            loss = loss_object(y_true=label_batch, y_pred=predictions)\n","        gradients = tape.gradient(loss, vgg16.trainable_variables)\n","        optimizer.apply_gradients(grads_and_vars=zip(gradients, vgg16.trainable_variables))\n","\n","        train_loss.update_state(values=loss)\n","        train_accuracy.update_state(y_true=label_batch, y_pred=predictions)\n","\n","    # @tf.function\n","    def valid_step(image_batch, label_batch):\n","        predictions = vgg16(image_batch, training=False)\n","        v_loss = loss_object(label_batch, predictions)\n","\n","        valid_loss.update_state(values=v_loss)\n","        valid_accuracy.update_state(y_true=label_batch, y_pred=predictions)\n","\n","    # start training\n","    for epoch in range(epochs):\n","        step = 0\n","        for features in train_data_gen:\n","            step += 1\n","            images, labels = features\n","            train_step(images, labels)\n","            print('.', end='')\n","                # print(\"Epoch: {}/{}, step: {}/{}, loss: {:.5f}, accuracy: {:.5f}\".format(epoch + 1,\n","                #                                                                         epochs,\n","                #                                                                         step,\n","                #                                                                          #현재 augmentation부분을 고려하지 않고 계산되는 부분 개선 필요.\n","                #                                                                         math.ceil(total_train / batch_size),\n","                #                                                                         train_loss.result().numpy(),\n","                #                                                                         train_accuracy.result().numpy()))\n","\n","        for features in val_data_gen:\n","            valid_images, valid_labels = features\n","            valid_step(valid_images, valid_labels)\n","        print('\\n')\n","        print(\"Epoch: {}/{}, train loss: {:.5f}, train accuracy: {:.5f}, \"\n","              \"valid loss: {:.5f}, valid accuracy: {:.5f}\".format(epoch + 1,\n","                                                                  epochs,\n","                                                                  train_loss.result().numpy(),\n","                                                                  train_accuracy.result().numpy(),\n","                                                                  valid_loss.result().numpy(),\n","                                                                  valid_accuracy.result().numpy()))\n","        train_loss.reset_states()\n","        train_accuracy.reset_states()\n","        valid_loss.reset_states()\n","        valid_accuracy.reset_states()\n","\n","        if (epoch + 1) % save_every_n_epoch == 0:\n","            model.save_weights(filepath=save_model_dir+\"epoch-{}\".format(epoch), save_format='tf')\n","\n","\n","    # save weights\n","    model.save_weights(filepath=save_model_dir+\"model\", save_format='tf')\n","\n","    # save the whole model\n","    # tf.saved_model.save(model, save_model_dir)\n","\n","    # convert to tensorflow lite format\n","    # model._set_inputs(inputs=tf.random.normal(shape=(1, IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS)))\n","    # converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","    # tflite_model = converter.convert()\n","    # open(\"converted_model.tflite\", \"wb\").write(tflite_model)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a74uKBnM49xv","colab_type":"code","colab":{}},"source":["#https://heartbeat.fritz.ai/reviewing-efficientnet-increasing-the-accuracy-and-robustness-of-cnns-6aaf411fc81d - EfficientNet 모델 사이트 굳굳!\n","#https://medium.com/analytics-vidhya/image-classification-with-efficientnet-better-performance-with-computational-efficiency-f480fdb00ac6 -여기도 굳굳!!"],"execution_count":0,"outputs":[]}]}